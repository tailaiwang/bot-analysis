# CS492 Social Bot Analysis Project

## Quickstart Guide for Reproducing Analysis Results

1. Follow [Reddit App Developer Guide](https://www.reddit.com/wiki/api/#wiki_read_the_full_api_terms_and_sign_up_for_usage) to get API access
2. Create `.env` file in `data/`

    CLIENT_ID=[ID] <br>
    CLIENT_SECRET=[SECRET THING] <br>
    (These values come from your Reddit Apps Page on your account profile)

3. Run `pip install -r requirements.txt` to install script dependencies
4. Run `scrape_accounts.py` to gather live public account data. Your raw data will be in the `scraped/` folder (see details below)
5. Run `aggregate_data.py` to prep data for model analysis. Your aggregated data will be in the `cleaned/` folder
6. Run each of the bot testing models via their respective python scripts.

    E.g. `python3 train_reddit_spam_bot_detector.py` to run the training set of research result #1


## Research Results

1. Testing [creme332/reddit-spam-bot-detector](https://github.com/creme332/reddit-spam-bot-detector)

    GitHub user `creme332` created a heuristic-based algorithm that attempts to classify bots based on account metadata (account age, posting frequency, verification status). Note that this heuristic-based algorithm is not deterministic for an account - if the metadata of the account changes, the model's prediction may change. The user warned that the model isn't very accurate, but we figured using metadata heuristics would provide an important baseline for what simple tools could do. The user trained their model on the data in `creme_training.bots` and `creme_training.humans`. We initially tried running the model on its own training data and reproduced the following results:

    Training Bot Detection Success Rate: 123 out of 352 bots (**35% accuracy**)
    Training Human Detection Success Rate: 166 out of 294 humans (**56% accuracy**)

    The abysmal results seem to indicate that the heuristic-based approach would like to avoid false-positives and overly predict "human" when possible. We then decided to test the model on our live data, and found some surprising results:

    Live Bot Detection Success Rate: 259 out of 444 bots (**58% accuracy**)
    Live Human Detection Success Rate: 399 out of 632 humans (**63% accuracy**)

    After taking some time to compare our live data with the original training data, we found a pattern that could explain the better performance on live data: the original accounts in the training data are now 2 years old, with some being inactive for some time. The metadata approach is more successful with active accounts, as the algorithm can use posting frequency in its weights. Thus, we believe that the **live success rate is more reflective of the algorithms real potential.**

	2. Testing [GPT-2 Output Detector](https://github.com/openai/gpt-2-output-dataset/tree/master/detector)

	When OpenAI released GPT2, they released a GPT2 detector free for the public to use. The model outputs a single likelihood metric which represents how confident the model is that the given text is generated by GPT2.

	In order to use this model, we downloaded the top 5 posts from all the bots in the training & live bots/humans datasets. We then appended each account's top comments together to create a (rough) paragraph of text that each bot/human account had created. These paragraphs were then given to the GPT2 detection model, and if the model returned a "bot likelihood" result of > 50%, we labeled the paragraph's author account as a bot. Below are the initial results ran on the same datasets as above.

	Training Bot Detection Success Rate: 127 out of 323 bots (**39.32% accuracy**)
	Training Human Detection Success Rate: 258 out of 290 humans (**88.97% accuracy**)

	Pretty bad numbers for the success rate on the training data! However, this kinda makes sense since this model is trained to detect GPT-generated text -- which differs significantly from comments generated by the bots in training dataset. The bots in the training dataset are primarily composed of spam-bots, auto-moderation bots, or other utility bots which generate very repetitive or hard-coded comments that a human originally wrote.

	Live Bot Detection Success Rate: 261 out of 438 bots (**59.59% accuracy**)
	Live Human Detection Success Rate: 515 out of 621 humans (**82.93% accuracy**)

	Initially it looks like only mediocre numbers for correctly detecting bots, however, our dataset included many types of bots -- bots with a GPT backend was only a small subset of all the bots. If we run the GPT detection algorithm on only the "GPT bots", we get a much better success rate:

	Live Bot Detection Success Rate (GPT in name): 107 out of 128 bots (**83.59% accuracy**)

